import json

with open("conversations.json", "r", encoding="utf-8") as f:
    data = json.load(f)



import json
import re

# --- Load the file ---
with open("conversations.json", "r", encoding="utf-8") as f:
    data = json.load(f)

# --- Extract user messages ---
user_messages = []

for convo in data:
    mapping = convo.get("mapping", {})
    for msg in mapping.values():
        message = msg.get("message")
        if not message:
            continue  # Skip if missing
        author = message.get("author", {})
        if author.get("role") == "user":
            parts = message.get("content", {}).get("parts", [])
            if parts and isinstance(parts[0], str):
                user_messages.append(parts[0])

# --- Filter: remove short, duplicate, and empty messages ---
filtered_messages = [
    msg for msg in set(user_messages)
    if len(msg.split()) >= 5 and re.search(r'\w', msg)
]

print(f"âœ… Total user messages extracted: {len(user_messages)}")
print(f"âœ… Messages after filtering: {len(filtered_messages)}")

# --- Save to TXT ---
with open("shooby_filtered_prompts.txt", "w", encoding="utf-8") as f:
    for msg in filtered_messages:
        f.write(msg.replace("\n", " ") + "\n")



import re

# Load the raw file
with open("shooby_filtered_prompts.txt", "r", encoding="utf-8") as f:
    prompts = [line.strip() for line in f if line.strip()]

# Function to remove undesirable patterns
def is_good_line(line):
    # Remove terminal prompts or git logs
    if re.search(r"\$\s|^\(base\)", line):
        return False
    # Remove file paths or stack traces
    if re.search(r"Traceback|File\s\"|\.py in <module>", line):
        return False
    # Remove long HTML, email headers, or markdown dump
    if re.search(r"From:.*@.*\s|Subject:|^https?://", line):
        return False
    # Remove CV-like blocks
    if re.search(r"(Caltech|NASA|Ureka|Ph\.D|Postdoctoral|Technical Skills|Experience)", line):
        return False
    # Remove matplotlib/pandas errors
    if "ValueError" in line or "matplotlib" in line or "pandas" in line:
        return False
    # Skip lines longer than 1000 characters (likely job apps or dumps)
    if len(line) > 1000:
        return False
    return True

# Apply filtering
cleaned_prompts = [line for line in prompts if is_good_line(line)]

print(f"âœ… Messages after full cleaning: {len(cleaned_prompts)}")

# Save the clean result
with open("shooby_cleaned_for_embedding.txt", "w", encoding="utf-8") as f:
    for line in cleaned_prompts:
        f.write(line + "\n")



import re

# Load current prompts
with open("shooby_cleaned_for_embedding.txt", "r", encoding="utf-8") as f:
    lines = [line.strip() for line in f if line.strip()]

cleaned_lines = []
for line in lines:
    # Skip lines that are too long (likely dumps, CVs, or markdown docs)
    if len(line) > 1000:
        continue
    # Skip tracebacks or python errors
    if any(kw in line.lower() for kw in ["traceback", "valueerror", "file \"/", "line in <module>", "matplotlib", "pandas", "ArrowInvalid"]):
        continue
    # Skip codey shell lines
    if re.match(r"^\(base\)|^\$|^ls\b|^git\b|^python\b", line):
        continue
    # Skip LaTeX-like citation lines
    if re.search(r"\\cite|\{.*@.*\}|\bibliographystyle", line):
        continue
    # Skip lines with email addresses
    if re.search(r"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+", line):
        continue
    # Redact phone numbers (simple version)
    line = re.sub(r"\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4}", "[REDACTED]", line)
    # Redact names/emails (optional)
    line = re.sub(r"\bShooby\b|\bShoubaneh\b", "[REDACTED]", line)
    
    cleaned_lines.append(line)

# Save polished file
with open("shooby_final_prompts.txt", "w", encoding="utf-8") as f:
    for line in cleaned_lines:
        f.write(line + "\n")

print(f"âœ… Final polished lines: {len(cleaned_lines)}")



from sentence_transformers import SentenceTransformer
import umap
import matplotlib.pyplot as plt
import pandas as pd

# Load prompts
with open("shooby_final_prompts.txt", "r", encoding="utf-8") as f:
    prompts = [line.strip() for line in f if len(line.strip()) > 5]

# Load sentence transformer
model = SentenceTransformer("all-MiniLM-L6-v2")
embeddings = model.encode(prompts)


# Reduce dimensions
reducer = umap.UMAP(n_neighbors=100, min_dist=0.9, metric='cosine')
embedding_2d = reducer.fit_transform(embeddings)

# Visualize
df = pd.DataFrame(embedding_2d, columns=["x", "y"])
df["prompt"] = prompts

plt.figure(figsize=(12, 8))
plt.scatter(df["x"], df["y"], alpha=0.6)
plt.title("UMAP Projection of Your Thoughts")
plt.axis('off')
plt.grid(True)
plt.show()



import plotly.express as px
import pandas as pd

# Prepare DataFrame
df_vis = pd.DataFrame(embedding_2d, columns=["UMAP 1", "UMAP 2"])
df_vis["message"] = prompts

# Plot
fig = px.scatter(
    df_vis,
    x="UMAP 1",
    y="UMAP 2",
    custom_data=["message"],  # only pass message to custom_data
    title="UMAP Projection of ShoobAI",
    opacity=0.5,
    height=600,
)

# Customize hover and hide axes
fig.update_traces(
    hovertemplate="<b>%{customdata[0]}</b><extra></extra>",  # show only the message
    marker=dict(size=7)
)
fig.update_layout(
    xaxis=dict(showgrid=False, zeroline=False, visible=False),
    yaxis=dict(showgrid=False, zeroline=False, visible=False),
    plot_bgcolor='rgba(255,255,255,0)',
)

fig.show()



import hdbscan
import plotly.express as px
import pandas as pd

# Cluster the UMAP-reduced embeddings
clusterer = hdbscan.HDBSCAN(min_cluster_size=30, prediction_data=True)
cluster_labels = clusterer.fit_predict(embedding_2d)

# Prepare DataFrame
df_vis = pd.DataFrame(embedding_2d, columns=["UMAP 1", "UMAP 2"])
df_vis["message"] = prompts
df_vis["cluster"] = cluster_labels.astype(str)  # Convert to string for plotting

# Plot with cluster coloring
fig = px.scatter(
    df_vis,
    x="UMAP 1",
    y="UMAP 2",
    color="cluster",
    custom_data=["message"],
    title="ðŸ§  UMAP Projection of ShoobAI (Color = Cluster)",
    opacity=0.65,
    height=700,
)

fig.update_traces(
    hovertemplate="<b>%{customdata[0]}</b><extra></extra>",
    marker=dict(size=5)
)
fig.update_layout(
    xaxis=dict(showgrid=False, zeroline=False, visible=False),
    yaxis=dict(showgrid=False, zeroline=False, visible=False),
    plot_bgcolor='rgba(255,255,255,0)',
    legend_title="Cluster",
)

fig.show()




